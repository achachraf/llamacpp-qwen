LLAMACPP_QWEN_PATH=/opt/llamacpp-qwen
BASE_MODELS_PATH=${LLAMACPP_QWEN_PATH}/models
QWEN_MODEL_PATH=${BASE_MODELS_PATH}/Qwen2.5-Coder-0.5B-Instruct
QWEN_MODEL_GGUF_PATH=${QWEN_MODEL_PATH}/qwen2.5-coder-0.5b-instruct-q2_k.gguf
GGUF_MODEL_URL="https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF/resolve/main/qwen2.5-coder-0.5b-instruct-q2_k.gguf?download=true"
LLAMA_SERVER_PORT=8080
LLAMA_SERVER_HOST=0.0.0.0

# Inference parameters
N_CTX=512
THREADS=4
TEMPERATURE=0.7
TOP_K=40
TOP_P=0.95